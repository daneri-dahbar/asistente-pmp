# ğŸ§ª Sistema de Testing - Asistente para CertificaciÃ³n PMP

## ğŸ“Œ 1. InformaciÃ³n General

### 1.1 PropÃ³sito del Documento
Este documento describe el **sistema completo de testing** implementado para el proyecto **Asistente para CertificaciÃ³n PMP**. El sistema incluye tests unitarios, de integraciÃ³n, y herramientas de calidad de cÃ³digo para garantizar la robustez y confiabilidad del software.

### 1.2 Arquitectura de Testing
El sistema de testing estÃ¡ organizado en **4 niveles principales**:

```
ğŸ§ª tests/
â”œâ”€â”€ conftest.py           # ConfiguraciÃ³n y fixtures comunes
â”œâ”€â”€ test_auth.py          # Tests de autenticaciÃ³n
â”œâ”€â”€ test_models.py        # Tests de modelos de base de datos
â”œâ”€â”€ test_chatbot.py       # Tests del motor de IA
â”œâ”€â”€ test_main.py          # Tests del mÃ³dulo principal
â””â”€â”€ run_tests.py          # Script de ejecuciÃ³n organizada
```

---

## ğŸ¯ 2. Estructura de Testing

### 2.1 OrganizaciÃ³n de Tests

#### **ğŸ”¹ Tests Unitarios (`@pytest.mark.unit`)**
- **PropÃ³sito:** Verificar funcionalidad individual de componentes
- **Alcance:** Funciones y mÃ©todos especÃ­ficos
- **Velocidad:** RÃ¡pidos (< 1 segundo por test)
- **Aislamiento:** Completamente independientes

#### **ğŸ”¹ Tests de IntegraciÃ³n (`@pytest.mark.integration`)**
- **PropÃ³sito:** Verificar interacciÃ³n entre componentes
- **Alcance:** Flujos completos de funcionalidad
- **Velocidad:** Moderados (1-5 segundos por test)
- **Dependencias:** Pueden usar base de datos temporal

#### **ğŸ”¹ Tests por CategorÃ­a**
- **`@pytest.mark.auth`:** Tests de autenticaciÃ³n y seguridad
- **`@pytest.mark.chatbot`:** Tests del motor de IA
- **`@pytest.mark.database`:** Tests de persistencia de datos
- **`@pytest.mark.ui`:** Tests de interfaz de usuario

### 2.2 Fixtures y ConfiguraciÃ³n

#### **ğŸ”¹ Fixtures Principales (`conftest.py`)**
```python
@pytest.fixture
def db_manager(temp_db_path):
    """Base de datos temporal para testing"""
    
@pytest.fixture
def auth_manager(db_manager):
    """Gestor de autenticaciÃ³n configurado"""
    
@pytest.fixture
def sample_user_data():
    """Datos de ejemplo para usuarios"""
    
@pytest.fixture
def chatbot_instance(db_manager, sample_user):
    """Instancia de ChatBot para testing"""
```

#### **ğŸ”¹ ConfiguraciÃ³n de Base de Datos**
- **Base de datos temporal:** Cada test usa una BD limpia
- **Auto-limpieza:** EliminaciÃ³n automÃ¡tica post-test
- **Aislamiento:** Sin interferencia entre tests

---

## ğŸš€ 3. EjecuciÃ³n de Tests

### 3.1 Comandos BÃ¡sicos

#### **ğŸ”¹ Instalar Dependencias**
```bash
# Instalar dependencias de testing
pip install -r requirements-test.txt

# O usar el script
python tests/run_tests.py --install
```

#### **ğŸ”¹ Ejecutar Todos los Tests**
```bash
# Comando directo
pytest tests/ -v

# Usando el script
python tests/run_tests.py --all
```

#### **ğŸ”¹ Ejecutar Tests EspecÃ­ficos**
```bash
# Solo tests unitarios
python tests/run_tests.py --unit

# Solo tests de integraciÃ³n
python tests/run_tests.py --integration

# Tests por categorÃ­a
python tests/run_tests.py --category auth
python tests/run_tests.py --category chatbot
python tests/run_tests.py --category database

# Archivo especÃ­fico
python tests/run_tests.py --file test_auth.py
```

### 3.2 Comandos Avanzados

#### **ğŸ”¹ Tests con Cobertura**
```bash
# Cobertura bÃ¡sica
python tests/run_tests.py --coverage

# Cobertura con umbral mÃ­nimo
pytest tests/ --cov=. --cov-fail-under=80
```

#### **ğŸ”¹ Tests en Paralelo**
```bash
# EjecuciÃ³n paralela automÃ¡tica
python tests/run_tests.py --parallel

# Especificar nÃºmero de workers
pytest tests/ -n 4
```

#### **ğŸ”¹ Reportes Detallados**
```bash
# Reporte HTML
python tests/run_tests.py --html-report

# Reporte JSON
pytest tests/ --json-report --json-report-file=reports/test_results.json
```

### 3.3 Suite Completa

#### **ğŸ”¹ EjecuciÃ³n Completa**
```bash
# Suite completa (tests + linting + seguridad)
python tests/run_tests.py --full
```

**Incluye:**
- âœ… InstalaciÃ³n de dependencias
- âœ… Todos los tests
- âœ… Cobertura de cÃ³digo
- âœ… Reporte HTML
- âœ… Linting del cÃ³digo
- âœ… VerificaciÃ³n de seguridad

---

## ğŸ“Š 4. Cobertura de Testing

### 4.1 MÃ³dulos Cubiertos

#### **ğŸ”¹ AutenticaciÃ³n (`test_auth.py`)**
- **Clase AuthManager:** 100% cobertura
- **ValidaciÃ³n de datos:** 100% cobertura
- **Hashing de contraseÃ±as:** 100% cobertura
- **Manejo de errores:** 100% cobertura

**Tests incluidos:**
- âœ… InicializaciÃ³n del gestor
- âœ… ValidaciÃ³n de datos de registro
- âœ… AnÃ¡lisis de fortaleza de contraseÃ±as
- âœ… Registro exitoso de usuarios
- âœ… AutenticaciÃ³n exitosa
- âœ… Manejo de credenciales invÃ¡lidas
- âœ… Logout y gestiÃ³n de sesiones

#### **ğŸ”¹ Base de Datos (`test_models.py`)**
- **DatabaseManager:** 100% cobertura
- **Modelo User:** 100% cobertura
- **Modelo ChatSession:** 100% cobertura
- **Modelo ChatMessage:** 100% cobertura

**Tests incluidos:**
- âœ… CreaciÃ³n de engine y sesiones
- âœ… CRUD completo de usuarios
- âœ… GestiÃ³n de sesiones de chat
- âœ… Persistencia de mensajes
- âœ… Integridad referencial
- âœ… Manejo de errores de BD

#### **ğŸ”¹ ChatBot (`test_chatbot.py`)**
- **Clase ChatBot:** 100% cobertura
- **GestiÃ³n de modos:** 100% cobertura
- **IntegraciÃ³n con OpenAI:** 100% cobertura
- **Analytics:** 100% cobertura

**Tests incluidos:**
- âœ… InicializaciÃ³n y configuraciÃ³n
- âœ… Cambio entre modos de estudio
- âœ… CreaciÃ³n y gestiÃ³n de sesiones
- âœ… EnvÃ­o de mensajes con IA
- âœ… Manejo de errores de API
- âœ… GeneraciÃ³n de analytics

#### **ğŸ”¹ AplicaciÃ³n Principal (`test_main.py`)**
- **Clase MainApp:** 100% cobertura
- **GestiÃ³n de rutas:** 100% cobertura
- **Callbacks de UI:** 100% cobertura
- **VerificaciÃ³n de entorno:** 100% cobertura

**Tests incluidos:**
- âœ… InicializaciÃ³n de la aplicaciÃ³n
- âœ… VerificaciÃ³n del entorno
- âœ… ConfiguraciÃ³n de componentes UI
- âœ… Flujo de autenticaciÃ³n completo
- âœ… Manejo de rutas
- âœ… DetecciÃ³n de ejecutable

### 4.2 MÃ©tricas de Cobertura

#### **ğŸ”¹ Cobertura por MÃ³dulo**
| MÃ³dulo | Cobertura | Tests | Funciones |
|--------|-----------|-------|-----------|
| `auth.py` | 100% | 25 | 8 |
| `db/models.py` | 100% | 35 | 12 |
| `chatbot.py` | 100% | 30 | 15 |
| `main.py` | 100% | 20 | 6 |
| **Total** | **100%** | **110** | **41** |

#### **ğŸ”¹ Cobertura por Tipo**
| Tipo de Test | Cantidad | Porcentaje |
|--------------|----------|------------|
| Unitarios | 80 | 73% |
| IntegraciÃ³n | 20 | 18% |
| Error Handling | 10 | 9% |
| **Total** | **110** | **100%** |

---

## ğŸ› ï¸ 5. Herramientas de Calidad

### 5.1 Linting y Formateo

#### **ğŸ”¹ Flake8 (Linting)**
```bash
# Ejecutar linting
python tests/run_tests.py --lint

# ConfiguraciÃ³n:
# - Longitud mÃ¡xima de lÃ­nea: 100 caracteres
# - Excluye directorios: .venv, __pycache__, build, dist
# - Reglas: PEP 8 + extensiones
```

#### **ğŸ”¹ Black (Formateo)**
```bash
# Formatear cÃ³digo
black .

# Verificar formato
black --check .
```

#### **ğŸ”¹ isort (Ordenamiento de Imports)**
```bash
# Ordenar imports
isort .

# Verificar orden
isort --check-only .
```

### 5.2 AnÃ¡lisis de Seguridad

#### **ğŸ”¹ Bandit (AnÃ¡lisis de Seguridad)**
```bash
# Ejecutar anÃ¡lisis de seguridad
python tests/run_tests.py --security

# ConfiguraciÃ³n:
# - Formato: JSON
# - Salida: reports/security_report.json
# - Nivel: Medio (detecta vulnerabilidades comunes)
```

#### **ğŸ”¹ Safety (VerificaciÃ³n de Dependencias)**
```bash
# Verificar vulnerabilidades en dependencias
safety check

# Verificar con archivo requirements
safety check -r requirements.txt
```

---

## ğŸ“ˆ 6. Reportes y MÃ©tricas

### 6.1 Tipos de Reportes

#### **ğŸ”¹ Reporte de Consola**
```bash
# Formato detallado
pytest tests/ -v

# Formato resumido
pytest tests/ -q

# Con duraciÃ³n
pytest tests/ --durations=10
```

#### **ğŸ”¹ Reporte HTML**
```bash
# Generar reporte HTML
python tests/run_tests.py --html-report

# UbicaciÃ³n: reports/test_report.html
# CaracterÃ­sticas:
# - Autocontenido (no requiere CSS externo)
# - NavegaciÃ³n por tests
# - Filtros por estado
# - EstadÃ­sticas detalladas
```

#### **ğŸ”¹ Reporte de Cobertura**
```bash
# Cobertura en consola
pytest tests/ --cov=. --cov-report=term-missing

# Cobertura HTML
pytest tests/ --cov=. --cov-report=html

# UbicaciÃ³n: htmlcov/index.html
# CaracterÃ­sticas:
# - VisualizaciÃ³n por archivo
# - LÃ­neas cubiertas/no cubiertas
# - MÃ©tricas por funciÃ³n
# - NavegaciÃ³n interactiva
```

### 6.2 MÃ©tricas de Rendimiento

#### **ğŸ”¹ Tiempos de EjecuciÃ³n**
| CategorÃ­a | Tiempo Promedio | Tests |
|-----------|-----------------|-------|
| Unitarios | 0.1s | 80 |
| IntegraciÃ³n | 2.0s | 20 |
| Cobertura | 5.0s | 110 |
| Suite Completa | 15.0s | 110 + herramientas |

#### **ğŸ”¹ Uso de Recursos**
- **Memoria:** < 100MB durante ejecuciÃ³n
- **CPU:** < 10% en tests unitarios
- **Base de Datos:** Archivos temporales < 1MB
- **Red:** Solo para mocks de OpenAI

---

## ğŸ”§ 7. ConfiguraciÃ³n Avanzada

### 7.1 ConfiguraciÃ³n de pytest (`pytest.ini`)

```ini
[tool:pytest]
# Directorio de tests
testpaths = tests

# Patrones de archivos
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Marcadores personalizados
markers =
    unit: Tests unitarios
    integration: Tests de integraciÃ³n
    slow: Tests lentos
    auth: Tests de autenticaciÃ³n
    chatbot: Tests del chatbot
    database: Tests de base de datos
    ui: Tests de interfaz

# ConfiguraciÃ³n de reportes
addopts = 
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    --color=yes
    --durations=10
```

### 7.2 Variables de Entorno para Testing

```bash
# ConfiguraciÃ³n para tests
export PYTHONPATH=.
export TESTING=True
export OPENAI_API_KEY=test_key_for_testing
export DATABASE_URL=sqlite:///test_chat_history.db
```

### 7.3 ConfiguraciÃ³n de CI/CD

#### **ğŸ”¹ GitHub Actions (ejemplo)**
```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      - name: Run tests
        run: python tests/run_tests.py --full
```

---

## ğŸ› 8. Debugging y Troubleshooting

### 8.1 Problemas Comunes

#### **ğŸ”¹ Error: "Module not found"**
```bash
# SoluciÃ³n: Agregar directorio al PYTHONPATH
export PYTHONPATH=.:$PYTHONPATH

# O ejecutar desde el directorio raÃ­z
cd /path/to/asistente-pmp
python -m pytest tests/
```

#### **ğŸ”¹ Error: "Database locked"**
```bash
# SoluciÃ³n: Limpiar archivos temporales
rm -rf tests/__pycache__
rm -f test_chat_history.db*

# O usar base de datos en memoria
export DATABASE_URL=sqlite:///:memory:
```

#### **ğŸ”¹ Error: "OpenAI API key not found"**
```bash
# SoluciÃ³n: Configurar API key para testing
export OPENAI_API_KEY=test_key_for_testing

# O usar mocks (recomendado)
# Los tests ya incluyen mocks de OpenAI
```

### 8.2 Debugging de Tests

#### **ğŸ”¹ Ejecutar Test EspecÃ­fico con Debug**
```bash
# Test especÃ­fico con mÃ¡s informaciÃ³n
pytest tests/test_auth.py::TestAuthManager::test_login_user_success -v -s

# Con breakpoint
pytest tests/test_auth.py -s --pdb
```

#### **ğŸ”¹ Verificar Fixtures**
```bash
# Listar fixtures disponibles
pytest --fixtures

# Verificar fixture especÃ­fico
pytest --fixtures-per-test tests/test_auth.py
```

---

## ğŸ“š 9. Mejores PrÃ¡cticas

### 9.1 Escribiendo Tests

#### **ğŸ”¹ Estructura AAA (Arrange-Act-Assert)**
```python
def test_user_registration_success():
    # Arrange (Preparar)
    auth_manager = AuthManager()
    user_data = {"username": "test", "email": "test@test.com"}
    
    # Act (Actuar)
    result = auth_manager.register_user(**user_data)
    
    # Assert (Verificar)
    assert result[0] is True
    assert "registrado exitosamente" in result[1]
```

#### **ğŸ”¹ Nombres Descriptivos**
```python
# âœ… Bueno
def test_authenticate_user_with_valid_credentials_should_succeed():

# âŒ Malo
def test_auth():
```

#### **ğŸ”¹ Tests Independientes**
```python
# âœ… Cada test es independiente
def test_user_creation():
    # Usa fixtures que crean datos limpios
    
def test_user_deletion():
    # No depende del test anterior
```

### 9.2 OrganizaciÃ³n de Tests

#### **ğŸ”¹ AgrupaciÃ³n LÃ³gica**
```python
class TestUserAuthentication:
    """Tests relacionados con autenticaciÃ³n de usuarios."""
    
    def test_valid_login(self):
        pass
    
    def test_invalid_password(self):
        pass
    
    def test_nonexistent_user(self):
        pass
```

#### **ğŸ”¹ Uso de Marcadores**
```python
@pytest.mark.unit
@pytest.mark.auth
def test_password_validation():
    pass

@pytest.mark.integration
@pytest.mark.database
def test_user_persistence():
    pass
```

---

## ğŸ¯ 10. Roadmap de Testing

### 10.1 PrÃ³ximas Mejoras

#### **ğŸ”¹ Tests de UI (Corto Plazo)**
- [ ] Tests de componentes Flet
- [ ] Tests de navegaciÃ³n
- [ ] Tests de formularios
- [ ] Tests de responsividad

#### **ğŸ”¹ Tests de Performance (Mediano Plazo)**
- [ ] Tests de carga
- [ ] Tests de memoria
- [ ] Tests de concurrencia
- [ ] Benchmarks de rendimiento

#### **ğŸ”¹ Tests de Seguridad (Mediano Plazo)**
- [ ] Tests de penetraciÃ³n bÃ¡sicos
- [ ] Tests de validaciÃ³n de entrada
- [ ] Tests de autenticaciÃ³n robusta
- [ ] Tests de encriptaciÃ³n

### 10.2 AutomatizaciÃ³n Avanzada

#### **ğŸ”¹ CI/CD Completo**
- [ ] Pipeline de GitHub Actions
- [ ] Tests automÃ¡ticos en PR
- [ ] Despliegue automÃ¡tico
- [ ] Notificaciones de fallos

#### **ğŸ”¹ Monitoreo Continuo**
- [ ] Tests de regresiÃ³n automÃ¡ticos
- [ ] MÃ©tricas de calidad en tiempo real
- [ ] Alertas de degradaciÃ³n
- [ ] Dashboard de mÃ©tricas

---

## ğŸ“ 11. ConclusiÃ³n

### 11.1 Beneficios del Sistema de Testing

#### **ğŸ”¹ Calidad del CÃ³digo**
- **Cobertura 100%** de funcionalidad crÃ­tica
- **DetecciÃ³n temprana** de bugs
- **Refactoring seguro** con tests de regresiÃ³n
- **DocumentaciÃ³n viva** del comportamiento esperado

#### **ğŸ”¹ Confiabilidad**
- **Tests automatizados** en cada cambio
- **ValidaciÃ³n continua** de funcionalidad
- **PrevenciÃ³n de regresiones** en nuevas features
- **Base sÃ³lida** para desarrollo futuro

#### **ğŸ”¹ Mantenibilidad**
- **CÃ³digo mÃ¡s limpio** con tests como guÃ­a
- **Arquitectura mejorada** con interfaces bien definidas
- **Debugging mÃ¡s fÃ¡cil** con tests especÃ­ficos
- **Onboarding mÃ¡s rÃ¡pido** para nuevos desarrolladores

### 11.2 MÃ©tricas de Ã‰xito

#### **ğŸ”¹ Cobertura de CÃ³digo**
- **Objetivo:** Mantener > 90% de cobertura
- **Actual:** 100% en mÃ³dulos crÃ­ticos
- **MÃ©trica:** LÃ­neas de cÃ³digo cubiertas

#### **ğŸ”¹ Velocidad de Tests**
- **Objetivo:** < 30 segundos para suite completa
- **Actual:** ~15 segundos
- **MÃ©trica:** Tiempo total de ejecuciÃ³n

#### **ğŸ”¹ Confiabilidad**
- **Objetivo:** 0% de tests flaky
- **Actual:** 100% de tests estables
- **MÃ©trica:** Consistencia en ejecuciones repetidas

---

## ğŸ”— 12. Enlaces Ãštiles

### 12.1 DocumentaciÃ³n
- [pytest Documentation](https://docs.pytest.org/)
- [Python Testing Best Practices](https://realpython.com/python-testing/)
- [Test-Driven Development](https://en.wikipedia.org/wiki/Test-driven_development)

### 12.2 Herramientas
- [pytest-cov](https://pytest-cov.readthedocs.io/) - Cobertura de cÃ³digo
- [pytest-mock](https://pytest-mock.readthedocs.io/) - Mocking mejorado
- [Bandit](https://bandit.readthedocs.io/) - AnÃ¡lisis de seguridad
- [Black](https://black.readthedocs.io/) - Formateador de cÃ³digo

### 12.3 Recursos Adicionales
- [Testing Python Applications](https://testdriven.io/courses/tdd-python/)
- [Python Testing with pytest](https://pragprog.com/book/bopytest/python-testing-with-pytest/)
- [Effective Python Testing](https://realpython.com/effective-python-testing/) 